### 1. 과제 소개
    
    로그 파일 분석하여 단위 시간 별 통계 파일 생성

![image](https://user-images.githubusercontent.com/28583661/71387359-d4e3a680-2636-11ea-9d1a-98ebb3434e64.png)

### 2. 요구사항

    1) 최초 실행 시에는 가장 오래된 날짜 로그 파일부터 '현재-1분'까지의 모든 로그를 처리하여 통계 파일을 생성
    2) access_날짜.txt -> 분석 -> yyyyMMddHHmm 파일 생성 -> 취합 -> yyyyMMddHH 파일 생성 -> 취합 -> stat_yyyy-MM-dd 파일 생성
    3) yyyyMMddHHmm 파일은 최근 60분 파일만 유지, yyyyMMddHH 파일은 최근 24시간 파일만 유지, stat_yyyy-MM-dd 파일은 모두 유지
    4) 모든 통계 파일은 로그 빈도수에 따라 내림차순으로 정렬을 수행하여 저장
    5) 실시간으로 처리될 수 있도록 구현
    
### 3. 추가 요구사항

    1) IP / EMAIL / METHOD / URL 속성을 갖는 모델 객체 활용
    2) equals(), hashCode() 재정의하여 통계 산출하는데 사용
    3) access_날짜.txt 파일을 하나의 맵 또는 리스트에 담는 것 제거
    4) 프로그램을 재시작 했을 때 이미 처리한 로그는 중복 처리 하지 않도록 구현

### 4. 핵심 코드

![image](https://user-images.githubusercontent.com/28583661/71388015-e5e1e700-2639-11ea-8576-bc24d4cff157.png)
      
    1) 라인을 읽어 나가면서 분 단위의 시간이 변했을 때 임시 저장소에 저장되어 있는 이전 라인들을 로컬에 저장하는 방법을 사용. 
    2) 이렇게 하면 메모리에 하나의 파일 단위가 아닌 분 단위의 라인들이 들어갈 것이기 때문에 메모리를 효율적으로 사용 가능.
    


    
